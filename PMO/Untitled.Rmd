---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import os                               # Operating system
import math                             # Mathematics
import numpy as np                      # Arrays
import pandas as pd                     # Dataframes
import matplotlib.pyplot as plt         # Graphs
from matplotlib import cm               # Colours
import scipy                            # Scientific computing
```

```{python}
stocks = [stock.split('.')[0] for stock in sorted(os.listdir('archive'))]
```

```{python}
print(stocks)
```

```{python}
len(stocks)
```

```{python}
ex_stock = pd.read_csv('archive/A2M.csv')
```

```{python}
ex_stock.head()
```

```{python}
ex_stock.tail()
```

```{python}
ex_stock.describe()
```

```{python}
ex_stock.info()
```

```{python}
dates = pd.date_range('2000-01-01', '2020-03-31')
data = pd.DataFrame({'Time': dates})
```

```{python}
for s in stocks:
    price = pd.read_csv('archive/' + s + '.csv', usecols=['Date', 'Adj Close']) #read file csv
    
    price['Date'] = pd.to_datetime(price['Date']) #Typecast date
    
    price.rename(columns={"Date": "Time", "Adj Close": s}, inplace=True) #rename column
    
    data = pd.merge(data, price, how='left', on=['Time'], sort=False) #merge table
```

```{python}
data.head()
```

```{python}
data['Time'].dt.weekday
```

```{python}
data = data[data['Time'].dt.weekday < 5]
```

```{python}
data.head()
```

```{python}
data = data.dropna(axis=0, how='all')
```

```{python}
data.head()
```

```{python}
r = data[(data['Time'].dt.weekday == 4) & (data['Time'] >= '2019-01-01')]
```

```{python}
r.head()
```

```{python}
r = r.drop(['Time'], axis=1)
```

```{python}
r
```

```{python}
r = r.pct_change(fill_method='ffill')
```

```{python}
r.head()
```

```{python}
p = data.drop(['Time'],axis=1).tail(1).to_numpy()
```

```{python}
p
```

```{python}
sigma = r.cov().to_numpy()
```

```{python}
sigma.shape
```

```{python}
mu = r.mean().to_numpy()
```

```{python}
mu.shape
```

```{python}
import cvxpy as cp 
```

```{python}
n = len(stocks)
```

```{python}
x = cp.Variable(shape=n, integer=True)
threshold = cp.Parameter(nonneg=True) # maximum portfolio variance
k = cp.Parameter(nonneg=True) # maximum allocation into one stock
```

```{python}
x
```

```{python}
threshold
```

```{python}
k
```

```{python}
mean = mu.T@x
variance = cp.quad_form(x, sigma)
```

```{python}
mean
```

```{python}
variance
```

```{python}
'{0:07b}'.format(1)
```

```{python}
ri = np.random.randint(50, size=100)
```

```{python}
sum(ri * p[0] > 3000)
```

```{python}
3000 / np.max(p)
```

```{python}
x = np.random.randint(100, size=100)
x_dna = '' 
for i in x:
    x_dna += '{0:07b}'.format(i)
```

```{python}
x_dna
```

```{python}
x
```

```{python}
def gen_pop(n):
    pop = []
    for _ in range(n):
        x = np.random.randint(100, size=100)
        x_dna = '' 
        for i in x:
            x_dna += '{0:07b}'.format(i)
        pop.append(x_dna)
    return pop
```

```{python}
a = gen_pop(3)
```

```{python}
len(x_dna)
```

```{python}
np.random.randint(0,100)
```

```{python}
k = '111000'
k[:3] + k[3:]
```

```{python}
i = np.random.randint(6)
j = k[i]
if j=='1':
    c = k[:i] + '0' + k[i+1:]
else:
    c = k[:i] + '1' + k[i+1:]
print(c)
```

```{python}
def xover(p1, p2):
    cross_point = np.random.randint(0, len(p1))
    
    child1 = p1[:cross_point] + p2[cross_point:]
    child2 = p2[:cross_point] + p1[cross_point:]
    
    return child1, child2
```

```{python}
a[0][1]
```

```{python}
a[1][1]
```

```{python}
p1, p2 = a[0][1], a[1][1]
```

```{python}
child1, child2 = xover(p1, p2)
```

```{python}
len(child1)
```

```{python}
def mutate(child):
    i = np.random.randint(len(child))
    j = child[i]
    
    if j=='1':
        mu = child[:i] + '0' + child[i+1:]
    else:
        mu = child[:i] + '1' + child[i+1:]
    return mu
```

```{python}
mutate(child1)
```

```{python}
def phenotype(dna):
    l = [dna[i * 7: i * 7 + 7] for i in range(100)]
    x = [int(n,2) for n in l]
    return np.array(x)
```

```{python}
ch = phenotype(child1)
```

```{python}
mu.T
```

```{python}
mu.T.dot(ch)
```

```{python}
ch.shape
```

```{python}
ch.T.dot(sigma).dot(ch)
```

```{python}
mu.shape
```

```{python}
ch.shape
```

```{python}
p
```

```{python}
sum(abs(mu[np.where(p[0]*ch > 3000)]))
```

```{python}
def evaluate(dna, mu, sigma, k, p):
    x = phenotype(dna)
    mean = mu.T.dot(x) 
    penalty = sum(abs(mu[np.where(p[0]*x > k)]))
    variance = 0.5 * x.T.dot(sigma).dot(x)
    
    return mean, 1 / variance, penalty
```

```{python}
vars()['a'] = 10
```

```{python}
population = gen_pop(10)
```

```{python}
phenotype(population[0])
```

```{python}
def is_pareto_efficient_simple(costs):
    """
    Find the pareto-efficient points
    :param costs: An (n_points, n_costs) array
    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient
    """
    is_efficient = np.ones(costs.shape[0], dtype = bool)
    for i, c in enumerate(costs):
        if is_efficient[i]:
            is_efficient[is_efficient] = np.any(costs[is_efficient] > c, axis=1)  # Keep any point with a lower cost
            is_efficient[i] = True  # And keep self
    return is_efficient
```

```{python}
C = [[0.3296170319979843, 0.0, 0.44472108843537406], [0.3296170319979843,0.0, 0.44472108843537406], [0.32920760896951373, 0.0, 0.4440408163265306], [0.32920760896951373, 0.0, 0.4440408163265306], [0.33815192743764166, 0.0, 0.44356462585034007]]
```

```{python}
C = np.array(Cost)
```

```{python}
l = []
cost = C
index = np.arange(len(cost))
while len(cost) > 0:
    b = is_pareto_efficient_simple(cost)
    l += index[b].tolist()
    index = index[b == 0]
    cost = cost[b == 0]
```

```{python}
C[l]
```

```{python}
def sorted_index(C):
    l = []
    cost = C
    index = np.arange(len(cost))
    while len(cost) > 0:
        b = is_pareto_efficient_simple(cost)
        l += index[b].tolist()
        index = index[b == 0]
        cost = cost[b == 0]
    
    return l
```

```{python}
sorted_index(C)
```

```{python}
a = np.array(C[l][0])
b = np.array(C[l][1])
c = np.array(C[l][-1])
```

```{python}
a>b
```

```{python}
a>c
```

```{python}
def fight(p1, p2):
    l = np.array([p1, p2])
    i = is_pareto_efficient_simple(l)
    print(i)
    return l[i][0].tolist()
```

```{python}
a = [0.32961703, 0.        , 0.44472109]
c = [0.32920761, 0.        , 0.44404082]
b = a
fight(c, b)
```

```{python}
np.array([[1], [2]])[[True, False]]
```

```{python}
p = ['a', 'b']
e = [a, b]
```

```{python}
def fight(parents, evaluates):
    l = np.array(evaluates)
    i = is_pareto_efficient_simple(l)
    
    return np.array(parents)[i][0].tolist()
```

```{python}
fight(p, e)
```

```{python}
import numpy as np

def pareto_frontier_multi(myArray):
    # Sort on first dimension
    myArray = myArray[myArray[:,0].argsort()]
    # Add first row to pareto_frontier
    pareto_frontier = myArray[0:1,:]
    # Test next row against the last row in pareto_frontier
    for row in myArray[1:,:]:
        if sum([row[x] >= pareto_frontier[-1][x]
                for x in range(len(row))]) == len(row):
            # If it is better on all features add the row to pareto_frontier
            pareto_frontier = np.concatenate((pareto_frontier, [row]))
    return pareto_frontier

def test():
    myArray = np.array([[1,1,1],[2,2,2],[4,4,4],[3,3,3]])
    print( pareto_frontier_multi(myArray))

test()
```

```{python}

```
